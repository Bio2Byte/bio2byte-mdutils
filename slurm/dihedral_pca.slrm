#!/usr/bin/env bash
#SBATCH --nodes=1
#SBATCH --ntasks=10
#SBATCH --mem-per-cpu=2G
#SBATCH --partition=##YOUR_PARTITION##
#SBATCH --time=4:00:00
#SBATCH -J dihedral_pca

echo ------------------------------------------------------
echo $SLURM_JOB_ID :: $SLURM_JOB_NAME
echo ------------------------------------------------------
echo SLURM: Job submitted from $SLURM_SUBMIT_HOST
echo SLURM: Job is running on $SLURM_JOB_PARTITION
echo -n "SLURM: Job running on node(s): "; echo "$SLURM_NODELIST"
echo SLURM: Working directory is "$SLURM_SUBMIT_DIR"
echo SLURM: Execution mode is $ENVIRONMENT
echo SLURM: \$PATH set to $PATH
echo ------------------------------------------------------

# MAKE SURE ALL MODULES ARE LOADED
# * parallel
# * Python environment with bio2byte-mdutils
EXEC_SCRIPT="mdutils-dihedral-pca"

cd "$SLURM_SUBMIT_DIR"

MD_DIRECTORIES=( )
for mddir in gg*gg/analy; do 
    [ -f $mddir/proj.xvg ] && continue
    [ -f $mddir/stripped.tpr ] || continue
    [ -f $mddir/stripped.xtc ] || continue
    MD_DIRECTORIES+=( "$mddir" )
done 

parallel -j $SLURM_NTASKS srun -N 1 -n 1 -c 1 --exact \
    "$EXEC_SCRIPT" \
        -s {}/stripped.tpr -f {}/stripped.xtc \
        -o {}/eigenval.xvg -v {}/eigenvec.trr \
        -j {}/proj.xvg \
        --first 1 --last 8 ::: ${MD_DIRECTORIES[@]}

exit
